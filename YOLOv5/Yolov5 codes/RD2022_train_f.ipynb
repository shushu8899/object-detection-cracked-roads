{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6286959-e05d-411b-9dc4-bb103ace391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=RDD2022_dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n",
      "YOLOv5  2024-6-17 Python-3.9.19 torch-2.3.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████| 14.1M/14.1M [00:00<00:00, 45.7MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\labels... 14081 images, 1788 backgrounds, 0 corrupt: 100%|██████████| 14081/14081 [00:44<00:00, 319.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\images\\Japan_006916.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\validation\\labels... 4024 images, 527 backgrounds, 0 corrupt: 100%|██████████| 4024/4024 [00:28<00:00, 142.42it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\validation\\labels.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.11 anchors/target, 0.993 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp4\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp4\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4         0G     0.0797    0.02874     0.0419          2        640: 100%|██████████| 881/881 [2:39:00<00:00, 10.83s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [16:54<00:00,  8.05s/it]\n",
      "                   all       4024       8398      0.499      0.252      0.203     0.0755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4         0G    0.06119    0.02506    0.02156          2        640: 100%|██████████| 881/881 [2:35:46<00:00, 10.61s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [16:04<00:00,  7.66s/it]\n",
      "                   all       4024       8398      0.468      0.347      0.301      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4         0G    0.05688    0.02484    0.01834          8        640: 100%|██████████| 881/881 [2:33:13<00:00, 10.44s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [16:22<00:00,  7.80s/it]\n",
      "                   all       4024       8398      0.475      0.474      0.445        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4         0G    0.05377    0.02447    0.01651          3        640: 100%|██████████| 881/881 [2:34:42<00:00, 10.54s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [17:08<00:00,  8.16s/it]\n",
      "                   all       4024       8398      0.545      0.504      0.503      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4         0G    0.05235     0.0241    0.01517          1        640: 100%|██████████| 881/881 [2:32:29<00:00, 10.38s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [16:27<00:00,  7.84s/it]\n",
      "                   all       4024       8398      0.557      0.547      0.548      0.269\n",
      "\n",
      "5 epochs completed in 14.305 hours.\n",
      "Optimizer stripped from runs\\train\\exp4\\weights\\last.pt, 14.5MB\n",
      "Optimizer stripped from runs\\train\\exp4\\weights\\best.pt, 14.5MB\n",
      "\n",
      "Validating runs\\train\\exp4\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [15:33<00:00,  7.41s/it]\n",
      "                   all       4024       8398      0.555      0.548      0.549      0.269\n",
      "                   D00       4024       2866      0.514      0.589      0.541      0.247\n",
      "                   D10       4024       1653      0.538      0.279       0.34      0.127\n",
      "                   D20       4024       1604      0.575      0.498      0.506      0.211\n",
      "                   D40       4024        548      0.375      0.401      0.339      0.135\n",
      "                   D43       4024        180      0.692      0.483      0.576      0.252\n",
      "                   D44       4024        785      0.547      0.569      0.538      0.288\n",
      "                   D50       4024        720      0.507        0.8      0.746      0.367\n",
      "                Repair       4024         42      0.692      0.762      0.804      0.527\n",
      "Results saved to \u001b[1mruns\\train\\exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run train.py --img 640 --epochs 5 --data RDD2022_dataset.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ccab5-86ec-4aac-964c-d0e3e7ec3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=runs/train/exp4/weights/last.pt, cfg=, data=RDD2022_dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n",
      "YOLOv5  2024-6-17 Python-3.9.19 torch-2.3.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 349/349 items from runs\\train\\exp4\\weights\\last.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\labels.cache... 14081 images, 1788 backgrounds, 0 corrupt: 100%|██████████| 14081/14081 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\images\\Japan_006916.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\validation\\labels.cache... 4024 images, 527 backgrounds, 0 corrupt: 100%|██████████| 4024/4024 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.11 anchors/target, 0.993 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp6\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp6\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4         0G     0.0486    0.02356    0.01341          2        640: 100%|██████████| 881/881 [3:13:33<00:00, 13.18s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [18:54<00:00,  9.00s/it]\n",
      "                   all       4024       8398      0.613       0.59      0.608      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4         0G    0.04895      0.023    0.01251          2        640: 100%|██████████| 881/881 [2:50:34<00:00, 11.62s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [19:30<00:00,  9.29s/it]\n",
      "                   all       4024       8398      0.555      0.561      0.556      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4         0G    0.04934    0.02352    0.01255          8        640: 100%|██████████| 881/881 [2:43:14<00:00, 11.12s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [17:06<00:00,  8.15s/it]\n",
      "                   all       4024       8398      0.529       0.51      0.496      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4         0G    0.04864    0.02348    0.01231          3        640: 100%|██████████| 881/881 [2:40:51<00:00, 10.96s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [16:30<00:00,  7.86s/it]\n",
      "                   all       4024       8398      0.618      0.588       0.59      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4         0G     0.0481    0.02327    0.01164          1        640: 100%|██████████| 881/881 [2:35:46<00:00, 10.61s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [16:17<00:00,  7.76s/it]\n",
      "                   all       4024       8398      0.589      0.593      0.586      0.304\n",
      "\n",
      "5 epochs completed in 15.541 hours.\n",
      "Optimizer stripped from runs\\train\\exp6\\weights\\last.pt, 14.5MB\n",
      "Optimizer stripped from runs\\train\\exp6\\weights\\best.pt, 14.5MB\n",
      "\n",
      "Validating runs\\train\\exp6\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [14:40<00:00,  6.99s/it]\n",
      "                   all       4024       8398      0.613       0.59      0.609      0.303\n",
      "                   D00       4024       2866      0.512      0.611      0.572      0.266\n",
      "                   D10       4024       1653      0.532      0.351      0.395      0.156\n",
      "                   D20       4024       1604      0.655      0.474      0.548      0.239\n",
      "                   D40       4024        548      0.471      0.422      0.399      0.154\n",
      "                   D43       4024        180      0.842      0.517       0.68      0.304\n",
      "                   D44       4024        785      0.541       0.67      0.606      0.344\n",
      "                   D50       4024        720      0.619      0.814      0.796      0.396\n",
      "                Repair       4024         42       0.73      0.857      0.874      0.565\n",
      "Results saved to \u001b[1mruns\\train\\exp6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run train.py --img 640 --epochs 5 --data RDD2022_dataset.yaml --weights runs/train/exp4/weights/last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e367d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train yolov5m 3 epochs\n",
    "%run train.py --img 640 --epochs 3 --data RDD2022_dataset.yaml -- weights yolov5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8417314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=runs/train/exp7/weights/last.pt, cfg=, data=RDD2022_dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m YOLOv5 is out of date by 6 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "YOLOv5  2024-6-17 Python-3.9.19 torch-2.3.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     60615  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20907687 parameters, 20907687 gradients, 48.3 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from runs\\train\\exp7\\weights\\last.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\labels.cache... 14081 images, 1788 backgrounds, 0 corrupt: 100%|██████████| 14081/14081 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\images\\Japan_006916.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\validation\\labels.cache... 4024 images, 527 backgrounds, 0 corrupt: 100%|██████████| 4024/4024 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.11 anchors/target, 0.993 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp12\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp12\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/2         0G    0.04788    0.02338    0.01398          2        640: 100%|██████████| 881/881 [5:30:09<00:00, 22.48s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [31:29<00:00, 15.00s/it]\n",
      "                   all       4024       8398      0.677       0.61       0.65      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/2         0G    0.04643    0.02232    0.01148          2        640: 100%|██████████| 881/881 [5:28:06<00:00, 22.35s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [33:33<00:00, 15.98s/it]\n",
      "                   all       4024       8398      0.635       0.61      0.615      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/2         0G    0.04357    0.02219    0.00981          8        640: 100%|██████████| 881/881 [5:32:40<00:00, 22.66s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [32:39<00:00, 15.55s/it]\n",
      "                   all       4024       8398      0.624      0.619      0.631      0.333\n",
      "\n",
      "3 epochs completed in 18.145 hours.\n",
      "Optimizer stripped from runs\\train\\exp12\\weights\\last.pt, 42.3MB\n",
      "Optimizer stripped from runs\\train\\exp12\\weights\\best.pt, 42.3MB\n",
      "\n",
      "Validating runs\\train\\exp12\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20889303 parameters, 0 gradients, 48.0 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [28:42<00:00, 13.67s/it]\n",
      "                   all       4024       8398      0.676       0.61       0.65      0.352\n",
      "                   D00       4024       2866      0.604      0.591      0.606      0.298\n",
      "                   D10       4024       1653      0.596      0.377      0.456      0.183\n",
      "                   D20       4024       1604      0.701      0.485      0.579       0.26\n",
      "                   D40       4024        548      0.622      0.453      0.476      0.199\n",
      "                   D43       4024        180       0.86      0.561      0.738      0.421\n",
      "                   D44       4024        785      0.549      0.697      0.613      0.347\n",
      "                   D50       4024        720      0.691      0.808      0.811      0.403\n",
      "                Repair       4024         42      0.787      0.905      0.919      0.704\n",
      "Results saved to \u001b[1mruns\\train\\exp12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train yolov5m another 3 epochs\n",
    "%run train.py --img 640 --epochs 3 --data RDD2022_dataset.yaml --weights runs/train/exp7/weights/last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c411f6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=runs/train/exp12/weights/last.pt, cfg=, data=RDD2022_dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=4, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m YOLOv5 is out of date by 7 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "YOLOv5  2024-6-17 Python-3.9.19 torch-2.3.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     60615  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20907687 parameters, 20907687 gradients, 48.3 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from runs\\train\\exp12\\weights\\last.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\labels.cache... 14081 images, 1788 backgrounds, 0 corrupt: 100%|██████████| 14081/14081 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\images\\Japan_006916.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\validation\\labels.cache... 4024 images, 527 backgrounds, 0 corrupt: 100%|██████████| 4024/4024 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.11 anchors/target, 0.993 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp13\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp13\u001b[0m\n",
      "Starting training for 4 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/3         0G    0.04361    0.02215    0.01058          2        640: 100%|██████████| 881/881 [6:27:15<00:00, 26.37s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [37:14<00:00, 17.74s/it]\n",
      "                   all       4024       8398      0.662      0.647      0.669      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/3         0G    0.04267    0.02113   0.007859          2        640: 100%|██████████| 881/881 [5:15:54<00:00, 21.51s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [29:56<00:00, 14.26s/it]\n",
      "                   all       4024       8398      0.616      0.619       0.61       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/3         0G    0.04168    0.02143   0.007623          8        640: 100%|██████████| 881/881 [6:40:55<00:00, 27.31s/it]    \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [38:04<00:00, 18.13s/it]\n",
      "                   all       4024       8398      0.557      0.587      0.581      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/3         0G    0.04605    0.02287    0.01244          3        640: 100%|██████████| 881/881 [5:56:53<00:00, 24.31s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [34:52<00:00, 16.60s/it]\n",
      "                   all       4024       8398      0.623      0.629      0.651      0.348\n",
      "\n",
      "4 epochs completed in 26.687 hours.\n",
      "Optimizer stripped from runs\\train\\exp13\\weights\\last.pt, 42.3MB\n",
      "Optimizer stripped from runs\\train\\exp13\\weights\\best.pt, 42.3MB\n",
      "\n",
      "Validating runs\\train\\exp13\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20889303 parameters, 0 gradients, 48.0 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [30:23<00:00, 14.47s/it]\n",
      "                   all       4024       8398      0.663      0.647      0.669      0.366\n",
      "                   D00       4024       2866      0.604      0.622       0.63      0.314\n",
      "                   D10       4024       1653      0.522      0.468      0.456      0.176\n",
      "                   D20       4024       1604      0.661      0.527      0.575      0.262\n",
      "                   D40       4024        548      0.566      0.502      0.524      0.209\n",
      "                   D43       4024        180      0.856      0.595       0.75      0.441\n",
      "                   D44       4024        785      0.568      0.706      0.633      0.368\n",
      "                   D50       4024        720       0.74      0.825       0.84      0.423\n",
      "                Repair       4024         42       0.79      0.929       0.94      0.737\n",
      "Results saved to \u001b[1mruns\\train\\exp13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train yolov5m another 4 epochs\n",
    "%run train.py --img 640 --epochs 4 --data RDD2022_dataset.yaml --weights runs/train/exp12/weights/last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72e464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=RDD2022_dataset.yaml, hyp=data/hyps/hyp.scratch-med.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m YOLOv5 is out of date by 2 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "YOLOv5  2024-6-17 Python-3.9.19 torch-2.3.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\labels.cache... 14081 images, 1788 backgrounds, 0 corrupt: 100%|██████████| 14081/14081 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\images\\Japan_006916.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\validation\\labels.cache... 4024 images, 527 backgrounds, 0 corrupt: 100%|██████████| 4024/4024 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.11 anchors/target, 0.993 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp9\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp9\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4         0G    0.08727    0.02135    0.02971         13        640: 100%|██████████| 881/881 [2:30:00<00:00, 10.22s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [16:05<00:00,  7.67s/it]\n",
      "                   all       4024       8398      0.536      0.147      0.102     0.0352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4         0G    0.07053    0.01925    0.01952          1        640: 100%|██████████| 881/881 [2:24:49<00:00,  9.86s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [15:30<00:00,  7.38s/it]\n",
      "                   all       4024       8398      0.473      0.317      0.278      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4         0G    0.06653    0.01894    0.01577          0        640: 100%|██████████| 881/881 [2:29:30<00:00, 10.18s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [15:48<00:00,  7.53s/it]\n",
      "                   all       4024       8398      0.501      0.344      0.316      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4         0G    0.06374    0.01875    0.01437          2        640: 100%|██████████| 881/881 [2:28:04<00:00, 10.09s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [15:52<00:00,  7.56s/it]\n",
      "                   all       4024       8398      0.491      0.451      0.428      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4         0G    0.06222    0.01825     0.0135          8        640: 100%|██████████| 881/881 [2:31:05<00:00, 10.29s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [16:31<00:00,  7.87s/it]\n",
      "                   all       4024       8398      0.567       0.48      0.479      0.206\n",
      "\n",
      "5 epochs completed in 13.724 hours.\n",
      "Optimizer stripped from runs\\train\\exp9\\weights\\last.pt, 14.5MB\n",
      "Optimizer stripped from runs\\train\\exp9\\weights\\best.pt, 14.5MB\n",
      "\n",
      "Validating runs\\train\\exp9\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [15:53<00:00,  7.57s/it]\n",
      "                   all       4024       8398      0.567      0.481       0.48      0.206\n",
      "                   D00       4024       2866      0.464      0.565      0.508      0.236\n",
      "                   D10       4024       1653      0.473      0.328      0.309      0.106\n",
      "                   D20       4024       1604      0.657       0.38      0.487      0.205\n",
      "                   D40       4024        548      0.468      0.263       0.26     0.0808\n",
      "                   D43       4024        180      0.657      0.533      0.587      0.215\n",
      "                   D44       4024        785      0.445      0.625      0.477      0.246\n",
      "                   D50       4024        720      0.534       0.75      0.689      0.301\n",
      "                Repair       4024         42      0.841      0.405      0.519      0.254\n",
      "Results saved to \u001b[1mruns\\train\\exp9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run train.py --img 640 --epochs 5 --data RDD2022_dataset.yaml --weights yolov5s.pt --hyp data/hyps/hyp.scratch-med.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2801362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=runs/train/exp9/weights/last.pt, cfg=, data=RDD2022_dataset.yaml, hyp=data/hyps/hyp.scratch-med.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m YOLOv5 is out of date by 6 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "YOLOv5  2024-6-17 Python-3.9.19 torch-2.3.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 349/349 items from runs\\train\\exp9\\weights\\last.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\labels.cache... 14081 images, 1788 backgrounds, 0 corrupt: 100%|██████████| 14081/14081 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\train\\images\\Japan_006916.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lowju\\SJ's files\\CS610\\RDD2022\\validation\\labels.cache... 4024 images, 527 backgrounds, 0 corrupt: 100%|██████████| 4024/4024 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.11 anchors/target, 0.993 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp11\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp11\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4         0G    0.05923    0.01809    0.01249         13        640: 100%|██████████| 881/881 [2:28:39<00:00, 10.12s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [15:40<00:00,  7.47s/it]\n",
      "                   all       4024       8398      0.584      0.542      0.555      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4         0G    0.05865    0.01798    0.01195          1        640: 100%|██████████| 881/881 [2:31:04<00:00, 10.29s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [15:17<00:00,  7.28s/it]\n",
      "                   all       4024       8398        0.6      0.544      0.557       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4         0G    0.05885    0.01812    0.01166          0        640: 100%|██████████| 881/881 [2:32:29<00:00, 10.39s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [15:43<00:00,  7.49s/it]\n",
      "                   all       4024       8398      0.497      0.491       0.48      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4         0G    0.05863    0.01821    0.01154          2        640: 100%|██████████| 881/881 [2:28:35<00:00, 10.12s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [15:31<00:00,  7.39s/it]\n",
      "                   all       4024       8398      0.579      0.506      0.524      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4         0G    0.05809    0.01784    0.01137          8        640: 100%|██████████| 881/881 [2:27:14<00:00, 10.03s/it]  \n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [16:30<00:00,  7.86s/it]\n",
      "                   all       4024       8398      0.551      0.536      0.525      0.238\n",
      "\n",
      "5 epochs completed in 13.781 hours.\n",
      "Optimizer stripped from runs\\train\\exp11\\weights\\last.pt, 14.5MB\n",
      "Optimizer stripped from runs\\train\\exp11\\weights\\best.pt, 14.5MB\n",
      "\n",
      "Validating runs\\train\\exp11\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 126/126 [13:48<00:00,  6.57s/it]\n",
      "                   all       4024       8398        0.6      0.544      0.556       0.28\n",
      "                   D00       4024       2866      0.551      0.486      0.508      0.229\n",
      "                   D10       4024       1653      0.505      0.417      0.392      0.145\n",
      "                   D20       4024       1604      0.706      0.429      0.534      0.235\n",
      "                   D40       4024        548      0.361      0.418      0.338      0.127\n",
      "                   D43       4024        180      0.734      0.522      0.614      0.328\n",
      "                   D44       4024        785       0.54      0.613      0.541      0.289\n",
      "                   D50       4024        720      0.666      0.725      0.733      0.358\n",
      "                Repair       4024         42       0.74      0.738       0.79       0.53\n",
      "Results saved to \u001b[1mruns\\train\\exp11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run train.py --img 640 --epochs 5 --data RDD2022_dataset.yaml --hyp data/hyps/hyp.scratch-med.yaml --weights runs/train/exp9/weights/last.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
